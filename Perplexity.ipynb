{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log,exp\n",
    "from n_gram import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# construct positive model\n",
    "txt = \"pos_pre.txt\"\n",
    "with open('%s' % txt,'r') as file:\n",
    "     file_str = file.read()\n",
    "file_str = file_str.replace('\\n',' ').split()\n",
    "\n",
    "length_pos,uni_word_pos,uni_cnt_pos,uni_prob_pos, \\\n",
    "bi_word_pos,bi_cnt_pos,bi_prob_pos,tri_word,tri_cnt_pos,tri_prob= gram(file_str)\n",
    "\n",
    "# Replace the word that occured once as UNK\n",
    "for i in range(0,len(file_str)):\n",
    "    if uni_cnt_pos[file_str[i]]==1:\n",
    "        file_str[i]='<UNK>'\n",
    "length_pos,uni_word_pos,uni_cnt_pos,uni_prob_pos, \\\n",
    "bi_word_pos,bi_cnt_pos,bi_prob_pos,tri_word,tri_cnt_pos,tri_prob= gram(file_str)\n",
    "\n",
    "# construct negative model\n",
    "txt = \"neg_pre.txt\"\n",
    "with open('%s' % txt,'r') as file:\n",
    "     file_str = file.read()\n",
    "file_str = file_str.replace('\\n',' ').split()\n",
    "\n",
    "length_neg,uni_word_neg,uni_cnt_neg,uni_prob_neg, \\\n",
    "bi_word_neg,bi_cnt_neg,bi_prob_neg,tri_word,tri_cnt_neg,tri_prob= gram(file_str)\n",
    "\n",
    "# Replace the word that occured once as UNK\n",
    "for i in range(0,len(file_str)):\n",
    "    if uni_cnt_neg[file_str[i]]==1:\n",
    "        file_str[i]='<UNK>'\n",
    "        \n",
    "length_neg,uni_word_neg,uni_cnt_neg,uni_prob_neg, \\\n",
    "bi_word_neg,bi_cnt_neg,bi_prob_neg,tri_word,tri_cnt_neg,tri_prob= gram(file_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions to calculate addK probability to unigram,bigram and trigram.\n",
    "\"\"\" \n",
    "def calc_addK_uni(k,word,length,uni_cnt):\n",
    "    if word in uni_cnt:\n",
    "        uni_prob = uni_cnt[word]\n",
    "    else: uni_prob = 0\n",
    "    return (uni_prob+k)/(length+k*len(uni_cnt.keys()))\n",
    "\n",
    "def calc_addK_bi(k,pre_word,word,bi_cnt,uni_cnt):\n",
    "    tuple = (pre_word,word)\n",
    "    if tuple in bi_cnt:\n",
    "        bi_prob = bi_cnt[tuple]\n",
    "    else: bi_prob = 0\n",
    "    if pre_word in uni_cnt:\n",
    "        uni_prob = uni_cnt[pre_word]\n",
    "    else: uni_prob = 0\n",
    "    return (bi_prob+k)/(uni_prob+k*len(uni_cnt.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "853.391670948\n",
      "818.413498439\n",
      "846.563856582\n",
      "793.61268013\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate the perplexity of smoothed unigram and bigram\n",
    "\"\"\"\n",
    "\n",
    "# combine pos dev and neg dev\n",
    "txt = \"pos_dev_pre.txt\"\n",
    "with open('%s' % txt,'r') as file:\n",
    "     file_str = file.readlines()\n",
    "\n",
    "txt = \"neg_dev_pre.txt\"\n",
    "with open('%s' % txt,'r') as file:\n",
    "     file_str_2 = file.readlines()\n",
    "file_str.extend(file_str_2)\n",
    "\n",
    "# calculate the perplexity of unigram and bigram for pos and neg model\n",
    "uni_pos_prob = 0\n",
    "bi_pos_prob = 0\n",
    "uni_neg_prob = 0\n",
    "bi_neg_prob = 0\n",
    "length = 0\n",
    "for line in file_str:\n",
    "    line = line.replace('\\n','').split()\n",
    "    pre_word = line[0]\n",
    "    for word in line[1:]:\n",
    "        uni_pos_prob += log(calc_addK_uni(1.5,word,length_pos,uni_cnt_pos))\n",
    "        bi_pos_prob += log(calc_addK_bi(0.1,pre_word,word,bi_cnt_pos,uni_cnt_pos))\n",
    "        uni_neg_prob += log(calc_addK_uni(1.5,word,length_neg,uni_cnt_neg))\n",
    "        bi_neg_prob += log(calc_addK_bi(0.1,pre_word,word,bi_cnt_neg,uni_cnt_neg))\n",
    "        pre_word = word\n",
    "    length += len(line)-1\n",
    "uni_pp_pos = exp(1.0/length*(-uni_pos_prob))\n",
    "bi_pp_pos = exp(1.0/length*(-bi_pos_prob))\n",
    "uni_pp_neg = exp(1.0/length*(-uni_neg_prob))\n",
    "bi_pp_neg = exp(1.0/length*(-bi_neg_prob))\n",
    "print(uni_pp_pos)\n",
    "print(bi_pp_pos)\n",
    "print(uni_pp_neg)\n",
    "print(bi_pp_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394074"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
